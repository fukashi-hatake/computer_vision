{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U3PZFfgUcwSg"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "metadata": {
        "id": "ue25rVo1c06U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w, b):\n",
        "  return w * t_u + b\n",
        "\n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "oKDk0kdLdFoS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.ones(())\n",
        "b = torch.zeros(())"
      ],
      "metadata": {
        "id": "u52EKHIhdTpC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_p = model(t_u, w, b)\n",
        "\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc9x9iEAdWqy",
        "outputId": "8ce2b723-58fc-4374-aba1-ea0f6e608e79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1763.8848)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(())\n",
        "y = torch.ones(3, 1)\n",
        "z = torch.ones(1, 3)\n",
        "a = torch.ones(2, 1, 1)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(z.shape)\n",
        "print(a.shape)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGjuud15dfky",
        "outputId": "296bfb0f-7d6a-4c21-8cb0-6c18773b5438"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n",
            "torch.Size([3, 1])\n",
            "torch.Size([1, 3])\n",
            "torch.Size([2, 1, 1])\n",
            "tensor(1.)\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "tensor([[1., 1., 1.]])\n",
            "tensor([[[1.]],\n",
            "\n",
            "        [[1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x * y\", (x * y).shape)\n",
        "print(\"y * z\", (y * z).shape)\n",
        "print(\"y * z * a\", (y * z * a).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_hdbDYwd4xy",
        "outputId": "b493f018-85c3-40f7-931e-5fe2e33aff4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x * y torch.Size([3, 1])\n",
            "y * z torch.Size([3, 3])\n",
            "y * z * a torch.Size([2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x * y\", (x * y))\n",
        "print(\"y * z\", (y * z))\n",
        "print(\"y * z * a\", (y * z * a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohpLQjzXd5Lx",
        "outputId": "904c0b53-773c-4669-aca4-58927d805135"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x * y tensor([[1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "y * z tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "y * z * a tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient"
      ],
      "metadata": {
        "id": "bc7QWx3PfP0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    if params.grad is not None: # Before computing the gradient for the current epoch, it ensures that any previous gradients stored in params.grad are reset to zero.\n",
        "      params.grad.zero_() # Why? Gradients in PyTorch accumulate by default, so clearing them is necessary to avoid incorrect updates.\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    # Check for nan loss\n",
        "    if torch.isnan(loss):\n",
        "        print(f\"Loss is nan at epoch {epoch}. Breaking the loop.\")\n",
        "        break  # Stop training if loss becomes nan\n",
        "\n",
        "    loss.backward() # Computes gradients of the loss with respect to the model parameters using backpropagation.\n",
        "\n",
        "    with torch.no_grad():  # torch.no_grad(): Temporarily disables gradient tracking for performance and ensures no accidental modification of gradients during parameter updates.\n",
        "      params -= learning_rate * params.grad\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "GMP2DjhvDjoO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(5000, 1e-2, torch.tensor([1.0, 0.0], requires_grad=True), t_u, t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTy9kBupFqjN",
        "outputId": "89b9e8af-c974-4d9f-d1d8-9186819714be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss is nan at epoch 23. Breaking the loop.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, inf], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = t_c / 10\n",
        "t_u = t_u / 10"
      ],
      "metadata": {
        "id": "MHAzOFH8GHut"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop( 5000, 1e-2, torch.tensor([1.0, 0.0], requires_grad=True), t_u, t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z30xLgeICSM",
        "outputId": "c984750f-b47b-45fb-81fd-0f93c5414625"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 0.070306\n",
            "Epoch 1000, Loss 0.036770\n",
            "Epoch 1500, Loss 0.030645\n",
            "Epoch 2000, Loss 0.029526\n",
            "Epoch 2500, Loss 0.029322\n",
            "Epoch 3000, Loss 0.029285\n",
            "Epoch 3500, Loss 0.029278\n",
            "Epoch 4000, Loss 0.029277\n",
            "Epoch 4500, Loss 0.029277\n",
            "Epoch 5000, Loss 0.029276\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5367, -1.7302], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "dir(optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faYuqoEBISZb",
        "outputId": "37e8806b-dd38-4848-a15e-da573404ef67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adafactor',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'NAdam',\n",
              " 'Optimizer',\n",
              " 'RAdam',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_adafactor',\n",
              " '_functional',\n",
              " 'lr_scheduler',\n",
              " 'swa_utils']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_with_optim(n_epochs, optimzer, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    if params.grad is not None: # Before computing the gradient for the current epoch, it ensures that any previous gradients stored in params.grad are reset to zero.\n",
        "      params.grad.zero_() # Why? Gradients in PyTorch accumulate by default, so clearing them is necessary to avoid incorrect updates.\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    # Check for nan loss\n",
        "    if torch.isnan(loss):\n",
        "        print(f\"Loss is nan at epoch {epoch}. Breaking the loop.\")\n",
        "        break  # Stop training if loss becomes nan\n",
        "\n",
        "    optimzer.zero_grad()\n",
        "\n",
        "    loss.backward() # Computes gradients of the loss with respect to the model parameters using backpropagation.\n",
        "\n",
        "    optimzer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "zdXkhP5BKCy8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([params], lr=1e-2)\n",
        "\n",
        "training_loop_with_optim(5000, optimizer, t_u, t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7H_XQ63LnBX",
        "outputId": "ba1780b8-7e8d-4727-821f-10610fdd2d85"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500, Loss 0.070306\n",
            "Epoch 1000, Loss 0.036770\n",
            "Epoch 1500, Loss 0.030645\n",
            "Epoch 2000, Loss 0.029526\n",
            "Epoch 2500, Loss 0.029322\n",
            "Epoch 3000, Loss 0.029285\n",
            "Epoch 3500, Loss 0.029278\n",
            "Epoch 4000, Loss 0.029277\n",
            "Epoch 4500, Loss 0.029277\n",
            "Epoch 5000, Loss 0.029276\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5367, -1.7302], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation dataset"
      ],
      "metadata": {
        "id": "jq9GHC3SOXmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)"
      ],
      "metadata": {
        "id": "He_kknF3MGXK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]"
      ],
      "metadata": {
        "id": "LNr3zlwVOay5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_t_c = t_c[train_indices]\n",
        "train_t_u = t_u[train_indices]\n",
        "\n",
        "val_t_c = t_c[val_indices]\n",
        "val_t_u = t_u[val_indices]"
      ],
      "metadata": {
        "id": "ZDPHvJaoOmFY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_with_validation(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    val_t_p = model(val_t_u, *params)\n",
        "    val_loss = loss_fn(val_t_p, val_t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training Loss {train_loss.item():.4f}, Validation Loss {val_loss.item():.4f}\")\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "wd2ARtV7Ouj5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop_with_validation(3000, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byggMrIBPGU4",
        "outputId": "da414d3c-dce2-400c-bb75-28914b3adea2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss 17.5343, Validation Loss 18.1093\n",
            "Epoch 2, Training Loss 3.1704, Validation Loss 2.6860\n",
            "Epoch 3, Training Loss 0.7793, Validation Loss 0.3268\n",
            "Epoch 500, Training Loss 0.0662, Validation Loss 0.0236\n",
            "Epoch 1000, Training Loss 0.0362, Validation Loss 0.0225\n",
            "Epoch 1500, Training Loss 0.0324, Validation Loss 0.0222\n",
            "Epoch 2000, Training Loss 0.0319, Validation Loss 0.0221\n",
            "Epoch 2500, Training Loss 0.0319, Validation Loss 0.0220\n",
            "Epoch 3000, Training Loss 0.0319, Validation Loss 0.0220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5308, -1.7263], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd nits and switching it off"
      ],
      "metadata": {
        "id": "TVM76UaIQveV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop_with_validation(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    train_t_p = model(train_t_u, *params)\n",
        "    train_loss = loss_fn(train_t_p, train_t_c)\n",
        "\n",
        "    with torch.no_grad():  # The with torch.no_grad(): block is used in this context to temporarily disable gradient computation. Here's why it is important in this function\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad == False\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training Loss {train_loss.item():.4f}, Validation Loss {val_loss.item():.4f}\")\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "G_ScMNdXPMp4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop_with_validation(3000, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr2njft-Q9cn",
        "outputId": "e94db68e-63a5-4013-f166-d0be38459bb5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss 17.5343, Validation Loss 18.1093\n",
            "Epoch 2, Training Loss 3.1704, Validation Loss 2.6860\n",
            "Epoch 3, Training Loss 0.7793, Validation Loss 0.3268\n",
            "Epoch 500, Training Loss 0.0662, Validation Loss 0.0236\n",
            "Epoch 1000, Training Loss 0.0362, Validation Loss 0.0225\n",
            "Epoch 1500, Training Loss 0.0324, Validation Loss 0.0222\n",
            "Epoch 2000, Training Loss 0.0319, Validation Loss 0.0221\n",
            "Epoch 2500, Training Loss 0.0319, Validation Loss 0.0220\n",
            "Epoch 3000, Training Loss 0.0319, Validation Loss 0.0220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5308, -1.7263], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TMB0oX-0_jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch.NN"
      ],
      "metadata": {
        "id": "S1t2kn3-0__n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "nK8j7wpAEwEC"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "\n",
        "\n",
        "t_c = torch.tensor(t_c).unsqueeze(1)\n",
        "t_u = torch.tensor(t_u).unsqueeze(1)\n",
        "\n",
        "t_c = t_c / 10\n",
        "t_u = t_u / 10"
      ],
      "metadata": {
        "id": "owC_yNC5Q_J3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-bb-9Th03t2",
        "outputId": "68fdd9e7-1ba3-49fa-8450-d39309aac76a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0500],\n",
              "        [ 1.4000],\n",
              "        [ 1.5000],\n",
              "        [ 2.8000],\n",
              "        [ 1.1000],\n",
              "        [ 0.8000],\n",
              "        [ 0.3000],\n",
              "        [-0.4000],\n",
              "        [ 0.6000],\n",
              "        [ 1.3000],\n",
              "        [ 2.1000]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_t_c = t_c[train_indices]\n",
        "train_t_u = t_u[train_indices]\n",
        "\n",
        "val_t_c = t_c[val_indices]\n",
        "val_t_u = t_u[val_indices]"
      ],
      "metadata": {
        "id": "nwUbQjPs2ESA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_t_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9SxeqZ52K4y",
        "outputId": "14091c89-b45b-4285-975b-1365618eca79"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4000],\n",
              "        [1.3000]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "linear_model = nn.Linear(1, 1)\n",
        "\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2) # this method call replaces [params]\n"
      ],
      "metadata": {
        "id": "Ahch5r-s04qF"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3fvZXj1Q7F",
        "outputId": "4c259caf-6349-48cd-b061-74d427e330a9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7c77c116d9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZo5bpZ91Z11",
        "outputId": "0dc9bc6e-96ce-4fb7-cda4-7a6d856161d9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.9991]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3387], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p_train = model(t_u_train)\n",
        "    loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "    t_p_val = model(t_u_val)\n",
        "    loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 1000 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "            f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "metadata": {
        "id": "LvpD4CJp1ce1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(1, 1)\n",
        "\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(10000, optimizer, linear_model, nn.MSELoss(), train_t_u, val_t_u, train_t_c, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vABG3uVd1zdF",
        "outputId": "904cbd90-da36-4f60-d95b-4d124b51bdb7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 21.0110, Validation loss 24.6163\n",
            "Epoch 1000, Training loss 0.0310, Validation loss 0.0300\n",
            "Epoch 2000, Training loss 0.0288, Validation loss 0.0321\n",
            "Epoch 3000, Training loss 0.0288, Validation loss 0.0324\n",
            "Epoch 4000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 5000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 6000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 7000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 8000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 9000, Training loss 0.0288, Validation loss 0.0325\n",
            "Epoch 10000, Training loss 0.0288, Validation loss 0.0325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMJQhtUr1-CF",
        "outputId": "ecdf0036-d773-4992-bd2b-a39f375714ff"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.5419]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgEBAnYZ2umU",
        "outputId": "059f058c-5e3a-44a0-ef3e-510633b2890e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-1.7473], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(1, 13),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(13, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "eRi0z5z-2wz0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ8m7sUWEz2k",
        "outputId": "a9d01b76-184c-4f26-b153-6551dfd66013"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42DVk00oE4zt",
        "outputId": "f60cf1bb-ef6c-4d14-aa0f-8a099a83bb73"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "    ('hidden_linear', nn.Linear(1, 8)),\n",
        "    ('hidden_activation', nn.Tanh()),\n",
        "    ('output_linear', nn.Linear(8, 1))\n",
        "]))"
      ],
      "metadata": {
        "id": "1SRX86E-FQ99"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FxUiP_BFsLt",
        "outputId": "dae62e60-b2f9-4cd8-979a-7b08bf8d7d2a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86_P-bZ9FtNM",
        "outputId": "5d14e1b1-cfed-45c4-b6d5-9f3ffb6de7fc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 1])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([1, 8])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model.output_linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnyAJsNFFwS9",
        "outputId": "cff15391-ab0a-41a5-c0e0-30bfce55842c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.2241], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
        "\n",
        "training_loop(10000, optimizer, seq_model, nn.MSELoss(), train_t_u, val_t_u, train_t_c, val_t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc78SrC6Gbrz",
        "outputId": "de83d251-9958-4a2f-fe99-c5b7b13feea3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.1554, Validation loss 2.1650\n",
            "Epoch 1000, Training loss 0.7886, Validation loss 0.0914\n",
            "Epoch 2000, Training loss 0.6889, Validation loss 0.0711\n",
            "Epoch 3000, Training loss 0.4225, Validation loss 0.0321\n",
            "Epoch 4000, Training loss 0.1991, Validation loss 0.0159\n",
            "Epoch 5000, Training loss 0.1009, Validation loss 0.0207\n",
            "Epoch 6000, Training loss 0.0630, Validation loss 0.0285\n",
            "Epoch 7000, Training loss 0.0473, Validation loss 0.0328\n",
            "Epoch 8000, Training loss 0.0392, Validation loss 0.0345\n",
            "Epoch 9000, Training loss 0.0343, Validation loss 0.0352\n",
            "Epoch 10000, Training loss 0.0309, Validation loss 0.0354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('output', seq_model(val_t_u))\n",
        "print('answer', val_t_c)\n",
        "print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMNQ80vpGvHt",
        "outputId": "e661fbe0-70e6-475e-d088-ca63ebb4dcf4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output tensor([[1.2931],\n",
            "        [1.5437]], grad_fn=<AddmmBackward0>)\n",
            "answer tensor([[1.4000],\n",
            "        [1.3000]])\n",
            "hidden tensor([[-0.0013],\n",
            "        [ 0.0008],\n",
            "        [-0.0032],\n",
            "        [-0.0016],\n",
            "        [-0.0014],\n",
            "        [ 0.0002],\n",
            "        [ 0.0028],\n",
            "        [ 0.0002]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "t_range = torch.arange(20., 60.).unsqueeze(1)\n",
        "\n",
        "fig = plt.figure(dpi=80)\n",
        "plt.xlabel(\"Fahrenheit\")\n",
        "plt.ylabel(\"Celsius\")\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
        "\n",
        "# plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n",
        "plt.plot(t_u.numpy(), seq_model(t_u).detach().numpy(), 'kx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "SLLUOK7-F7Yt",
        "outputId": "b1324879-1d24-487a-f532-ec5cafe78fae"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c77c0206dd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 512x384 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTTUY6NPGQRt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}